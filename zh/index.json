[{"authors":["admin"],"categories":null,"content":"赵思源是携程机票大数据团队的算法工程师。\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"zh","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://127.0.0.1/zh/author/%E6%80%9D%E6%BA%90/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%80%9D%E6%BA%90/","section":"authors","summary":"赵思源是携程机票大数据团队的算法工程师。","tags":null,"title":"思源","type":"authors"},{"authors":null,"categories":["AI"],"content":"这本书很适合查漏补缺，我将其中精华的部分摘录并加入一些补充和代码实践。\n目录\r 特征工程  有哪些文本表示模型？它们各自有什么的优缺点？ Word2Vec 是如何工作的？它和 LDA 有什么区别与联系？ 在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？   模型评估  准确率的局限性？ 精确率与召回率的权衡？ 平方根误差的“意外” 什么是 ROC 曲线？ 如何绘制 ROC 曲线？ 如何计算 AUC ？ ROC 曲线相比 P-R 曲线有什么特点？ 为什么在一些场景中要使用余弦相似度而不是欧氏距离？ 余弦距离是否是一个严格定义的距离？ 在对模型进行充分的离线评估后，为什么还要进行在线的 A/B 测试？ 进行线上 A/B 测试？ 如何划分实验组和对照组？ 在模型评估过程中，有哪些主要的验证方法，它们的优缺点是什么？ 在自助法的采样过程中，对n个样本进行n次自助抽样，当n趋于无穷大时，最终有多少数据从未被选择过？ 超参数有哪些调优方法？ 在模型评估过程中，过拟合和欠拟合具体是指什么现象？ 能否说出几种降低过拟合和欠拟合风险的方法？   经典算法  \r特征工程 有哪些文本表示模型？它们各自有什么的优缺点？ 词袋模型 Bags of Words，TF-IDF Term Frequency-Inverse Document Frequency $$ TF-IDF(t,d) = TF(t,d)\\times IDF(t) $$\n其中 $TF(t,d)$ 为单词 $t$ 在文档 $d$ 中出现的频率, $IDF(t)$ 是逆文档频率，用来衡量单词 $t$ 对表达语义所起的重要性，如果一个单词在多个文章中出现，那么该词就是一个通用的词所有对其权重做出一定的惩罚，\n$$ IDF(t) = \\log \\frac{文章总数}{包含单词 t 的文章总数} $$\n将文章进行单词级别的划分有时候并不是一种好的做法，比如英文中的 natural language processing（自然语言处理）一词，如果将 natural，language，processing 这 3个词拆分开来，所表达的含义与三个词连续出现时大相径庭。通常，可以将连续出现的n个词（n≤N）组成的词组（N-gram）也作为一个单独的特征放到向量表示中去，构成 N-gram 模型。\n主题模型 Topic Model 基于词袋模型或 N-gram 模型的文本表示模型有一个明显的缺陷，就是无法识别出两个不同的词或词组具有相同的主题。因此，需要一种技术能够将具有相同主题的词或词组映射到同一维度上去，于是产生了主题模型。主题模型是一种特殊的概图模型。想象一下我们如何判定两个不同的词具有相同的主题呢？这两个词可能有更高的概率同时出现在同一篇文档中；换句话说，给定某一主题，这两个词的产生概率都是比较高的，而另一些不太相关的词汇产生的概率则是较低的。假设有K个主题，我们就把任意文章表示成一个K维的主题向量，其中向量的每一维代表一个主题，权重代表这篇文章属于这个特定主题的概率。主题模型所解决的事情，就是从文本库中发现有代表性的主题（得到每个主题上面词的分布），并且计算出每篇文章对应着哪些主题。\n词嵌入模型 Word Embedding 词嵌入是一类将词向量化的模型的统称，核心思想是将每个词都映射成低维空间（通常K=50～300维）上的一个稠密向量（Dense Vector）。K维空间的每一维也可以看作一个隐含的主题，只不过不像主题模型中的主题那样直观。由于词嵌入将每个词映射成一个K维的向量，如果一篇文档有N个词，就可以用一个N×K维的矩阵来表示这篇文档。\nWord2Vec 是如何工作的？它和 LDA 有什么区别与联系？ CBOW 的目标是根据上下文出现的词语来预测当前词的生成概率，如图所示；而 Skip-gram 是根据当前词来预测上下文中各词的生成概率。其中 w(t) 是当前所关注的词，w(t−2)、w(t−1)、w(t+1)、w(t+2) 是上下文中出现的词。这里前后滑动窗口大小均设为2。CBOW 和 Skip-gram 都可以表示成由输入层（Input）、映射层（Projection）和输出层（Output）组成的神经网络。输入层中的每个词由独热编码方式表示，即所有词均表示成一个N维向量，其中N为词汇表中单词的总数。在向量中，每个词都将与之对应的维度置为1，其余维度的值均设为0。在映射层（又称隐含层）中，K个隐含单元（Hidden Units）的取值可以由N维输入向量以及连接输入和隐含单元之间的N×K维权重矩阵计算得到。在 CBOW 中，还需要将各个输入词所计算出的隐含单元求和。同理，输出层向量的值可以通过隐含层向量（K维），以及连接隐含层和输出层之间的 K×N 维权重矩阵计算得到。输出层也是一个N维向量，每维与词汇表中的一个单词相对应。最后，对输出层向量应用 Softmax 激活函数，可以计算出每个单词的生成概率。\n谈到 Word2Vec 与 LDA 的区别和联系，首先，LDA 是利用文档中单词的共现关系来对单词按主题聚类，也可以理解为对“文档-单词”矩阵进行分解，得到“文档-主题”和“主题-单词”两个概率分布。而 Word2Vec 其实是对“上下文-单词”矩阵进行学习，其中上下文由周围的几个单词组成，由此得到的词向量表示更多地融入了上下文共现的特征。也就是说，如果两个单词所对应的 Word2Vec 向量相似度较高，那么它们很可能经常在同样的上下文中出现。\n需要说明的是，上述分析的是 LDA 与 Word2Vec 的不同，不应该作为主题模型和词嵌入两类方法的主要差异。主题模型通过一定的结构调整可以基于“上下文-单词”矩阵进行主题推理。同样地，词嵌入方法也可以根据“文档-单词”矩阵学习出词的隐含向量表示。主题模型和词嵌入两类方法最大的不同其实在于模型本身，主题模型是一种基于概率图模型的生成式模型，其似然函数可以写成若干条件概率连乘的形式，其中包括需要推测的隐含变量（即主题）；而词嵌入模型一般表达为神经网络的形式，似然函数定义在网络的输出之上，需要通过学习网络的权重以得到单词的稠密向量表示。\n在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？ 一个模型所能提供的信息一般来源于两个方面，一是训练数据中蕴含的信息；二是在模型的形成过程中（包括构造、学习、推理等），人们提供的先验信息。当训练数据不足时，说明模型从原始数据中获取的信息比较少，这种情况下要想保证模型的效果，就需要更多先验信息。先验信息可以作用在模型上，例如让模型采用特定的内在结构、条件假设或添加其他一些约束条件；先验信息也可以直接施加在数据集上，即根据特定的先验假设去调整、变换或扩展训练数据，让其展现出更多的、更有用的信息，以利于后续模型的训练和学习。\n具体到图像分类任务上，**训练数据不足带来的问题主要表现在过拟合方面，即模型在训练样本上的效果可能不错，但在测试集上的泛化效果不佳。**根据上述讨论，对应的处理方法大致也可以分两类：\n  一是基于模型的方法，主要是采用降低过拟合风险的措施，包括：\n简化模型（如将非线性模型简化为线性模型）、添加约束项以缩小假设空间（如L1/L2正则项）、集成学习、Dropout超参数等；\n  二是基于数据的方法，主要通过数据扩充（Data Augmentation），即根据一些先验知 识，在保持特定信息的前提下，对原始数据进行适当变换以达到扩充数据集的效果。\n具体到图像分类任务中，在保持图像类别不变的前提下，可以对训练集中的每幅图像进行以下变换。\n 一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等，这些变换对应着同一个目标在不同角度的观察结果。 对图像中的像素添加噪声扰动，比如椒盐噪声、高斯白噪声等。 颜色变换。例如，在图像的 RGB 颜色空间上进行主成分分析，得到 3 个主成分的特征向量 p1,p2,p3 及其对应的特征值 λ1,λ2,λ3，然后在每个像素的RGB 值上添加增量 $[p1,p2,p3]\\cdot[α1λ1,α2λ2,α3λ3]^T$，其中 α1,α2,α3 是均值为 0、方差较小的高斯分布随机数。 改变图像的亮度、清晰度、对比度、锐度等    模型评估 准确率的局限性？ 准确率是指分类正确的样本占总样本个数的比例，即 $$ accuracy = \\frac{n_{correct}}{n_{total}} $$ 其中 $n_{correct}$ 为被正确分类的样本个数，$n_{total}$ 为总样本的个数。 准确率是分类问题中最简单也是最直观的评价指标，但存在明显的缺陷。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。所以，当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。为了解决这个问题，可以使用更为有效的平均准确率（每个类别下的样本准确率的算术平均）作为模型评估的指标。\nTOP-N Accuracy, accuracy@N 正样本标签在模型预测可能性最高的前 N 个中的占比。\n精确率与召回率的权衡？ Hulu提供视频的模糊搜索功能，搜索排序模型返回的Top 5的精确率非常高，但在实际使用过程中，用户还是经常找不到想要的视频，特别是一些比较冷门的剧集，这可能是哪个环节出了问题呢？\n精确率 Precision是指分类正确的正样本个数占分类器判定为正样本的样本个数的比例。\n召回率 Recall是指分类正确的正样本个数占真正的正样本个数的比例。\nPrecision 值和 Recall 值是既矛盾又统一的两个指标，为了提高 Precision 值，分类器需要尽量在“更有把握”时才把样本预测为正样本，但此时往往会因为过于保守而漏掉很多“没有把握”的正样本，导致 Recall 值降低。\n在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用 Top N 返回结果的 Precision 值和 Recall 值来衡量排序模型的性能，即认为模型返回的 Top N 的结果就是模型判定的正样本，然后计算前 N 个位置上的准确率 Precision@N 和前 N 个位置上的召回率 Recall@N。\n回到问题中来，模型返回的 Precision@5 的结果非常好，也就是说排序模型 Top5 的返回值的质量是很高的。但在实际应用过程中，用户为了找一些冷门的视频，往往会寻找排在较靠后位置的结果，甚至翻页去查找目标视频。但根据题目描述，用户经常找不到想要的视频，这说明模型没有把相关的视频都找出来呈现给用户。显然，问题出在召回率上。如果相关结果有100个，即使 Precision@5 达到了 100%，Recall@5 也仅仅是 5%。在模型评估时，我们是否应该同时关注 Precision 值和 Recall 值？进一步而言，是否应该选取不同的 Top N 的结果进行观察呢？是否应该选取更高阶的评估指标来更全面地反映模型在 Precision 值和 Recall 值两方面的表现？\n答案都是肯定的，为了综合评估一个排序模型的好坏，不仅要看模型在不同 Top N 下的 Precision@N 和 Recall@N，而且最绘制出模型的 P-R（Precision-Recall）曲线。这里简单介绍一下 P-R 曲线的绘制方法。P-R 曲线的横轴是召回率，纵轴是精确率。对于一个排序模型来说，其 P-R 曲线上的一个点代表着，在某一阈值下，模型将大于该阈值的结果判定为正样本，小于该阈值的结果判定为负样本，此时返回结果对应的召回率和精确率。整条 P-R 曲线是通过将阈值从高到低移动而生成的。\n除此之外，F1 score 和 ROC 曲线也能综合地反映一个排序模型的性能。F1 score 是精准率和召回率的调和平均值，它定义为： $$ F1 = \\frac{2\\times precision \\times recall}{precision + recall} $$\n平方根误差的“意外” Hulu 作为一家流媒体公司，拥有众多的美剧资源，预测每部美剧的流量趋势对于广告投放、用户增长都非常重要。我们希望构建一个回归模型来预测某部美剧的流量趋势，但无论采用哪种回归模型，得到的 RMSE 指标都非常高。然而事实是，模型在 95% 的时间区间内的预测误差都小于 1%，取得了相当不错的预测结果。那么，造成 RMSE 指标居高不下的最可能的原因是什么？ $$ RMSE = \\frac{\\sum_{i=1}^{n}({y_i-\\hat{y}_i})^2}{n} $$ 一般情况下，RMSE 能够很好地反映回归模型预测值与真实值的偏离程度。但在实际问题中，如果存在个别偏离程度非常大的离群点（Outlier）时，即使离群点数量非常少，也会让 RMSE 指标变得很差。回到问题中来，模型在 95% 的时间区间内的预测误差都小于 1%，这说明，在大部分时间区间内，模型的预测效果都是非常优秀的。然而，RMSE 却一直很差，这很可能是由于在其他的 5% 时间区间内存在非常严重的离群点。事实上，在流量预估这个问题中，噪声点确实是很容易产生的，比如流量特别小的美剧、刚上映的美剧或者刚获奖的美剧，甚至一些相关社交媒体突发事件带来的流量，都可能会造成离群点。\n针对这个问题，有什么解决方案呢？可以从三个角度来思考。第一，如果我们认定这些离群点是“噪声点”的话，就需要在数据预处理的阶段把这些噪声点过滤掉。第二，如果不认为这些离群点是“噪声点”的话，就需要进一步提高模型的预测能力，将离群点产生的机制建模进去（这是一个宏大的话题，这里就不展开讨论了）。第三，可以找一个更合适的指标来评估该模型。关于评估指标，其实是存在比RMSE的鲁棒性更好的指标，比如平均绝对百分比误差（Mean Absolute Percent Error MAPE），它定义为: $$ MAPE = \\sum_{i}^{N}|\\frac{y_i-\\hat{y_i}}{y_i}|\\times\\frac{100}{n} $$ 相比 RMSE，MAPE 相当于把每个点的误差进行了归一化，降低了个别离群点带来的绝对误差的影响。\n什么是 ROC 曲线？ ROC 曲线是 Receiver Operating Characteristic Curve 的简称，中文名为“受试者工作特征曲线”。ROC 曲线源于军事领域，而后在医学领域应用甚广，“受试者工作特征曲线”这一名称也正是来自于医学领域。ROC 曲线的横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性率（True Positive Rate，TPR）。FPR 和 TPR 的计算方法分别为： $$ FPR = \\frac{FP}{N} $$\n$$ TPR = \\frac{TP}{P} $$\n其中，P 是真实正样本数量，N 是真实负样本数量，TP 是 P 个正样本中被分类器预测为正样本的个数，FP 是 N 个负样本中被分类器预测为正样本的个数。\n如何绘制 ROC 曲线？ 事实上，ROC 曲线是通过不断移动分类器的“截断点”来生成曲线上的一组关键点的，通过下面的例子进一步来解释“截断点”的概念。 在二值分类问题中，模型的输出一般都是预测样本为正例的概率。样本按照预测概率从高到低排序。在输出最终的正例、负例之前，我们需要指定一个阈值，预测概率大于该阈值的样本会被判为正例，小于该阈值的样本则会被判为负例。\n通过动态地调整截断点，从最高的得分开始（实际上是从正无穷开始，对应着 ROC 曲线的零点），逐渐调整到最低得分，每一个截断点都会对应一个 FPR和 TPR，在 ROC 图上绘制出每个截断点对应的位置，再连接所有点就得到最终的 ROC 曲线。\n下图为一个完美的 ROC 曲线，不管预测阈值如何变化，模型完美的预测出所有正负样本，此时在该曲线上只有一个点（FPR=0，TPR=1），此时 AUC 为 1。\n如何计算 AUC ？ 顾名思义，AUC （Area Under Curve）指的是 ROC 曲线下的面积大小，该值能够量化地反映基于 ROC 曲线衡量出的模型性能。计算 AUC 值只需要沿着 ROC 横轴做积分就可以了。由于 ROC 曲线一般都处于 y=x 这条直线的上方（如果不是的话，只要把模型预测的概率反转成 1−p 就可以得到一个更好的分类器），所以 AUC 的取值一般在 0.5～1 之间。AUC 越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。\nROC 曲线相比 P-R 曲线有什么特点？ 相比 P-R 曲线，ROC 曲线有一个特点，当正负样本的分布发生变化时，ROC 曲线的形状能够基本保持不变，而 P-R 曲线的形状一般会发生较剧烈的变化。\n在很多实际问题中，正负样本数量往往很不均衡。比如，计算广告领域经常涉及转化率模型，正样本的数量往往是负样本数量的 1/1000 甚至 1/10000。若选择不同的测试集，P-R 曲线的变化就会非常大，而 ROC 曲线则能够更加稳定地反映模型本身的好坏。所以，ROC 曲线的适用场景更多，被广泛用于排序、推荐、广告等领域。但需要注意的是，选择 P-R 曲线还是 ROC 曲线是因实际问题而异的，如果研究者希望更多地看到模型在特定数据集上的表现，P-R 曲线则能够更直观地反映其性能。\n为什么在一些场景中要使用余弦相似度而不是欧氏距离？ $$ \\cos(\\textbf{A},\\textbf{B}) = \\frac{\\textbf{A}\\cdot \\textbf{B}}{||\\textbf{A}||_2 ||\\textbf{B}||_2} =\\frac{\\sum_{1}^n a_i b_i}{\\sqrt{\\sum_{1}^n a_i^2}\\sqrt{\\sum_{1}^n b_i^2}} $$\nimport numpy as np\rfrom math import sqrt\rdef norm(x):\rres = 0\rfor i in x:\rres += i*i\rreturn sqrt(res)\rdef cos_sim(A, B):\rres = 0\rfor a, b in zip(A, B):\rres += a*b\rreturn res/(norm(A)*norm(B))\rdef cos_sim_np(A, B):\rreturn np.dot(A, B)/(np.linalg.norm(A)*np.linalg.norm(B))\r 对于两个向量A和B，其余弦相似度定义为，即两个向量夹角的余弦，关注的是向量之间的角度关系，并不关心它们的绝对大小，其取值范围是 $[−1,1]$。当一对文本相似度的长度差距很大、但内容相近时，如果使用词频或词向量作为特征，它们在特征空间中的的欧氏距离通常很大；而如果使用余弦相似度的话，它们之间的夹角可能很小，因而相似度高。此外，在文本、图像、视频等领域，研究的对象的特征维度往往很高，余弦相似度在高维情况下依然保持“相同时为1，正交时为0，相反时为−1”的性质，而欧氏距离的数值则受维度的影响，范围不固定，并且含义也比较模糊。\n在一些场景，例如Word2Vec中，其向量的模长是经过归一化的，此时欧氏距离与余弦距离有着单调的关系，即 $$ ||\\mathbf{A}-\\mathbf{B}||_2=\\sqrt{2(1-\\cos(\\mathbf{A},\\mathbf{B}))} $$ 其中$||\\mathbf{A}-\\mathbf{B}||_2$表示欧氏距离，$\\cos(\\mathbf{A},\\mathbf{B})$表示余弦相似度，$1-\\cos(\\mathbf{A},\\mathbf{B})$表示余弦距离。在此场景下，如果选择距离最小（相似度最大）的近邻，那么使用余弦相似度和欧氏距离的结果是相同的。\n总体来说，欧氏距离体现数值上的绝对差异，而余弦距离体现方向上的相对差异。例如，统计两部剧的用户观看行为，用户A的观看向量为 (0,1)，用户B为 (1,0)；此时二者的余弦距离很大，而欧氏距离很小；我们分析两个用户对于不同视频的偏好，更关注相对差异，显然应当使用余弦距离。而当我们分析用户活跃度，以登陆次数(单位：次)和平均观看时长(单位：分钟)作为特征时，余弦距离会认为 (1,10)、(10,100) 两个用户距离很近；但显然这两个用户活跃度是有着极大差异的，此时我们更关注数值绝对差异，应当使用欧氏距离。\n特定的度量方法适用于什么样的问题，需要在学习和研究中多总结和思考，这样不仅仅对面试有帮助，在遇到新的问题时也可以活学活用。\n余弦距离是否是一个严格定义的距离？ 不是，距离有三个性质：\n 正定性 对称性 三角不等式  在对模型进行充分的离线评估后，为什么还要进行在线的 A/B 测试？  离线评估无法完全消除过拟合的影响。 离线评估无法完全还原线上的工程环境。比如线上环境的延迟，数据丢失，标签数据确是等情况。因此，离线评估的结果是理想工程环境下的结果。 线上系统的某些商业指标在离线评估中无法计算。离线评估一般是针对模型本身进行评估，而与模型相关的其他指标，特别是商业指标，往往无法直接获得。比如，上线了新的推荐算法，离线评估往往关注的是ROC曲线、P-R曲线等的改进，而线上评估可以全面了解该推荐算法带来的用户点击率、留存时长、PV访问量等的变化。这些都要由A/B测试来进行全面的评估。  进行线上 A/B 测试？ 进行 A/B 测试的主要手段是进行用户分桶，即将用户分成实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型。在分桶的过程中，要注意样本的独立性和采样方式的无偏性，确保同一个用户每次只能分到同一个桶中，在分桶过程中所选取的 user_id 需要是一个随机数，这样才能保证桶中的样本是无偏的。\n如何划分实验组和对照组？ H公司的算法工程师们最近针对系统中的“美国用户”研发了一套全新的视频推荐模型A，而目前正在使用的针对全体用户的推荐模型是B。在正式上线之前，工程师们希望通过A/B测试来验证新推荐模型的效果。下面有三种实验组和对照组的划分方法，请指出哪种划分方法是正确的？ （1）根据user_id（user_id完全随机生成）个位数的奇偶性将用户划分为实验组和对照组，对实验组施以推荐模型A，对照组施以推荐模型B； （2）将user_id个位数为奇数且为美国用户的作为实验组，其余用户为对照组； （3）将user_id个位数为奇数且为美国用户的作为实验组，user_id个位数为偶数的用户作为对照组。\n上述3种 A/B 测试的划分方法都不正确。我们用包含关系图来说明三种划分方法，如图2.4所示。方法1 没有区分是否为美国用户，实验组和对照组的实验结果均有稀释；方法2的实验组选取无误，并将其余所有用户划分为对照组，导致对照组的结果被稀释；方法3的对照组存在偏差。正确的做法是将所有美国用户根据user_id个位数划分为试验组合对照组，分别施以模型A和B，才能够验证模型A的效果。\n在模型评估过程中，有哪些主要的验证方法，它们的优缺点是什么？   Holdout检验\nHoldout 检验是最简单也是最直接的验证方法，它将原始的样本集合随机划分成训练集和验证集两部分。比方说，对于一个点击率预测模型，我们把样本按照 70%～30% 的比例分成两部分，70% 的样本用于模型训练；30% 的样本用于模型验证，包括绘制 ROC 曲线、计算精确率和召回率等指标来评估模型性能。Holdout 检验的缺点很明显，即在验证集上计算出来的最后评估指标与原始分组有很大关系。为了消除随机性，研究者们引入了“交叉检验”的思想。\n  交叉检验\nk-fold 交叉验证：首先将全部样本划分成 k 个大小相等的样本子集；依次遍历这 k 个子集，每次把当前子集作为验证集，其余所有子集作为训练集，进行模型的训练和评估；最后把 k 次评估指标的平均值作为最终的评估指标。在实际实验中，k 经常取 10。\n  自助法 Bootstrap\n不管是Holdout 检验还是交叉检验，都是基于划分训练集和测试集的方法进行模型评估的。然而，当样本规模比较小时，将样本集进行划分会让训练集进一步减小，这可能会影响模型训练效果。有没有能维持训练集样本规模的验证方法呢？自助法可以比较好地解决这个问题。\n自助法是基于自助采样法的检验方法。对于总数为 n 的样本集合，进行 n 次有放回的随机抽样，得到大小为 n 的训练集。n 次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，将这些没有被抽出的样本作为验证集，进行模型验证，这就是自助法的验证过程。\n  在自助法的采样过程中，对n个样本进行n次自助抽样，当n趋于无穷大时，最终有多少数据从未被选择过？ 一个样本在一次抽样中未被抽中的概率为 $(1-\\frac{1}{n})$\nn 次抽样均未被抽中的概率为 $(1-\\frac{1}{n})^n$\n所以\n$$ \\begin{aligned} \\lim _{n\\rightarrow \\infty} (1-\\frac{1}{n})^n \u0026amp;= \\lim _{n\\rightarrow \\infty}(\\frac{n-1}{n})^n \\\\\n\u0026amp;=\\lim _{n\\rightarrow \\infty}(\\frac{1}{1+\\frac{1}{n-1}})^n \\\\\n\u0026amp;= \\frac{1}{\\lim _{n\\rightarrow \\infty}(1+\\frac{1}{n-1})^{n-1}} *\\frac{1}{\\lim _{n\\rightarrow \\infty}(1+\\frac{1}{n-1}) } \\\\\n\u0026amp;=\\frac{1}{e} *1 (重要极限) \\\\\n\u0026amp;\\approx 0.368 \\end{aligned} $$\n因此，当样本数很大时，大约有36.8%的样本从未被选择过，可作为验证集。\n超参数有哪些调优方法？ 为了进行超参数调优，我们一般会采用网格搜索、随机搜索、贝叶斯优化等算法。在具体介绍算法之前，需要明确超参数搜索算法一般包括哪几个要素。一是目标函数，即算法需要最大化/最小化的目标；二是搜索范围，一般通过上限和下限来确定；三是算法的其他参数，如搜索步长。\n一、网格搜索\n网格搜索可能是最简单、应用最广泛的超参数搜索算法，它通过查找搜索范围内的所有的点来确定最优值。如果采用较大的搜索范围以及较小的步长，网格搜索有很大概率找到全局最优值。然而，这种搜索方案十分消耗计算资源和时间，特别是需要调优的超参数比较多的时候。因此，在实际应用中，网格搜索法一般会先使用较广的搜索范围和较大的步长，来寻找全局最优值可能的位置；然后会逐渐缩小搜索范围和步长，来寻找更精确的最优值。这种操作方案可以降低所需的时间和计算量，但由于目标函数一般是非凸的，所以很可能会错过全局最优值。\n二、随机搜索\n随机搜索的思想与网格搜索比较相似，只是不再测试上界和下界之间的所有值，而是在搜索范围中随机选取样本点。它的理论依据是，如果样本点集足够大，那么通过随机采样也能大概率地找到全局最优值，或其近似值。随机搜索般会比网格搜索要快一些，但是和网格搜索的快速版一样，它的结果也是没法保证的。\n三、贝叶斯搜索\n贝叶斯优化算法在寻找最优最值参数时，采用了与网格搜索、随机搜索完全不同的方法。网格搜索和随机搜索在测试一个新点时，会忽略前一个点的信息；而贝叶斯优化算法则充分利用了之前的信息。\n贝叶斯优化算法通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。具体来说，它学习目标函数形状的方法是，首先根据先验分布，假设一个搜集函数；然后，每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布；最后，算法测试由后验分布给出的全局最值最可能出现的位置的点。对于贝叶斯优化算法，有一个需要注意的地方，一旦找到了一个局部最优值，它会在该区域不断采样，所以很容易陷入局部最优值。为了弥补这个缺陷，贝叶斯优化算法会在探索和利用之间找到一个平衡点，“探索”就是在还未取样的区域获取采样点；而“利用”则是根据后验分布在最可能出现全局最值的区域进行采样。\n在模型评估过程中，过拟合和欠拟合具体是指什么现象？ 过拟合是指模型对于训练数据拟合呈过当的情况，反映到评估指标上，就是模型在训练集上的表现很好，但在测试集和新数据上的表现较差。欠拟合指的是模型在训练和预测时表现都不好的情况。欠拟合时，模型没有很好地捕捉到数据的特征，不能够很好地拟合数据。过拟合时，模型过于复杂，把噪声数据的特征也学习到模型中，导致模型泛化能力下降，在后期应用过程中很容易输出错误的预测结果。\n能否说出几种降低过拟合和欠拟合风险的方法？   降低“过拟合”风险的方法\n  从数据入手，获得更多的训练数据。使用更多的训练数据是解决过拟合问题最有效的手段，因为更多的样本能够让模型学习到更多更有效的特征，减噪声的影响。当然，直接增加实验数据一般是很困难的，但是可以通过一定的规则来扩充训练数据。比如，在图像分类的问题上，可以通过图像的平移、旋转、缩放等方式扩充数据；更进一步地，可以使用生成式对抗网络来合成大量的新训练数据。\n  降低模型复杂度。在数据较少时，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免模型拟合过多的采样噪声。例如，在神经网络模型中减少网络层数、神经元个数等；在决策树模型中降低树的深度、进行剪枝等。\n  正则化方法。给模型的参数加上一定的正则约束，比如将权值的大小加入到损失函数中。以L2正则化为例： $$ C = C_0 + \\frac{\\lambda}{2n}\\cdot \\sum_iw_i^2 $$\n这样，在优化原来的目标函数 $c_0$ 的同时，也能避免权值过大带来的过拟合风险。\n  集成学习方法。集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险，如Bagging方法。\n    降低“欠拟合”风险的方法\n 添加新特征。当特征不足或者现有特征与样本标签的相关性不强时，模型容易出现欠拟合。通过挖掘“上下文特征”“ID类特征”“组合特征”等新的特征，往往能够取得更好的效果。在深度学习潮流中，有很多模型可以帮助完成特征工程，如因子分解机、梯度提升决策树、Deep-crossing等都可以成为丰富特征的方法。 增加模型复杂度。简单模型的学习能力较差，通过增加模型的复杂度可以使模型拥有更强的拟合能力。例如，在线性模型中添加高次项，在神经网络模型中增加网络层数或神经元个数等。 减小正则化系数。正则化是用来防止过拟合的，但当模型出现欠拟合现象时，则需要有针对性地减小正则化系数。    经典算法","date":1587658380,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1587658380,"objectID":"e924cea464c0dbbe5bfa8f4e508def1d","permalink":"https://127.0.0.1/zh/post/the-quest-for-machine-learning/","publishdate":"2020-04-24T00:13:00+08:00","relpermalink":"/zh/post/the-quest-for-machine-learning/","section":"post","summary":"这本书很适合查漏补缺，我将其中精华的部分摘录并加入一些补充和代码实践。\n","tags":["machine learning"],"title":"读《百面机器学习》","type":"post"},{"authors":["Q. Xiao","S. Zhao"],"categories":null,"content":"","date":1570030200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1570030200,"objectID":"9bb6d4886e0526250dea694e4ceb9591","permalink":"https://127.0.0.1/zh/talk/agifors/","publishdate":"2019-10-02T08:30:00-07:00","relpermalink":"/zh/talk/agifors/","section":"talk","summary":"Load factor measures a flight’s capacity utilization. For a route with multiple flights, load factor is more relevant and has less fluctuation. In this presentation, we proposed a novel machine learning approach to predict load factor progression at route level based on search and transaction data from Ctrip, China’s leading Online Travel Agency (OTA). Huge volumes of visitor-initiated inquiries are received on OTA’s platform, which with its distinctive ability to tag searches to visitors, provide insights on market demand. Features such as route popularity are derived from search data. Historical load factor and real-time sales are available from transaction records. These information are then put together in the model which predicts the load factor at each future date up until departure. We found that without using price as input, our model achieves high accuracy with an average mean absolute error of 2%~6% depending on future dates to departure.","tags":["Seq2Seq"],"title":"AGIFORS 59th Symposium","type":"talk"},{"authors":null,"categories":["CS"],"content":"工作后，陆陆续续也做了几个项目，本书中所提到的几个注意点确实深有体会。这本能够围绕提高代码可读性这个原则，介绍了从变量名、注释、控制流、表达式、类/方法等多个方面优化代码的方法。这个读书笔记总结了作者的主要想法，起到了快速查阅的作用。\n既然本书是关于提高代码可读性的，那么提高代码可读性到底重不重要呢？\n我认为答案并非绝对的。对于书中提到的那些一劳永逸即可提升的点，最好仔细理解并贯彻，比如变量的命名方式，函数的结构等等，这些其实是节省自己以及别人未来的时间。\n对于另一些每次运用都需要花费额外时间的点，比如额外的注释等等，建议哪怕项目再赶，宏观级注释也是需要的，因为它不需要花费过多额外的时间，却至少这可以帮助到未来的自己理解代码。\n剩下的就见仁见智了，也许未来的我们都会有新的理解。\n附：豆瓣地址: 中文版，\r英文版\n目录\r 前言、代码应当易于理解 一、表面层次的改进  把信息装到变量的名字中 不会误解的名字 审美 改写什么样的注释 写出言简意赅的注释   二、简化循环和逻辑  让控制流变得易读 拆分超长的表达式 变量与可读性   三、重新组织代码  抽取不相干的子问题 一次只做一件事 把想法变成代码 少写代码   四、精选话题  测试与可读性    \r前言、代码应当易于理解   可读性基本定理\n 代码的写法应当使别人理解它所需的时间最小化。\n   一、表面层次的改进 把信息装到变量的名字中   选择专业的词\n 比如将下表左列指代不清的词换成右列中更为细分的词       单词 其他选择     get fetch, download   stop kill, pause, resume   send deliver, dispatch, distribute   find search, locate, extract   start launch, create, begin, open   make create, build, add, compose, new      避免泛泛的词\n 避免 tmp 这种泛泛的词 好的名字应当描述变量的目的或者它所承载的值  如用sum_squares 代替 tmp tmp如果是文件，则用 tmp_file 更好 循环迭代器 i, j, k 如果循环太多，容易搞混，最好用它所循环的变量名作为前缀如club_i, member_i, user_i 或者 ci, mi, ui 代替      用具体的名字代替抽象的名字\n 哪些名字非常抽象呢，想象自己是一个新加入项目的成员，能否快速通过名字知道这个变量所表达的信息    为名字附带更多的信息\n  后缀加单位\n 如 start -\u0026gt; start_ms    附带其他信息\n  未处理的变量前加 raw_\n  如纯文本的密码变量 pwd -\u0026gt; plaintext_pwd\n  匈牙利表示法是严谨的此类方法的命名系统\n它把变量的类型信息放在了变量名最前面如\npLast表示数据结构中最后一个元素的指针\n      名字要不要太长\n  怎么选择变量名的长短，如\n d, days, days_since_last_update    小的作用域里写短名字\n  代码补全可以让输入长名字不再痛苦\n  只是用通用的缩略词，避免首字母缩略\n 比如 str -\u0026gt; string 是很通用的写法 LF -\u0026gt; Load Factor 就容易让人费解    拿掉不会损失信息的词\n ConverToString - \u0026gt; ToString    利用名字的格式来传递含义\n  类变量后面加后缀offset_\n  全部大写表示常量 MAX_FILE_CNT\n      不会误解的名字 多问自己几遍：“这个名字会被解读成其他的含义吗？”\n  如 filter 究竟是过滤剩下的还是直接减去的意思？\n  max_length 如果代表最大字符数，用max_chars 更好，因为length 指代不清晰\n  使用 min 和 max 代表极限值，这样就可以明确是 \u0026gt; 和 \u0026lt; 而不是\u0026gt;=和\u0026lt;= 了\n  使用 first 和 last 来代表包含的范围\n  使用 begin 和 end 来代表排除的范围\n end代表刚好超过最后一个值    布尔值命名前加上is, has, can, should\n 避免使用反义词    与使用者的期望匹配\n get() 和 size() 给人很容易得到的感觉，如果是要计算均值用compute_mean（） 比 get_mean()好    审美   审美三原则\n 使用一致的布局 相似的代码看上去相似 把相关的代码行分组，形成代码块  把相似的想法归类 提供“脚印” 便于段落间的导航      变量申明调用时，使用有意义的顺序\n 如果在一段代码提到A、 B 和 C， 那么不要在另 一段中说 B、 C 和 A。 选择一个有意义的顺序， 并始终用这样的顺序。    把申明按逻辑组织起来\n 用空行和注释把不同阶段的代码分开来    个人风格的一致性\n 缩进 换行处    改写什么样的注释  注释的目的是为了帮助读者了解的和作者一样多\n   当我们写代码时，脑海里有很多有价值的信息，但是读者除了注释能看到的只有代码，所以注释包含的信息非常重要\n  哪些不需要注释\n  没有提供新的信息\n  不能帮助读者更好的理代码\n  不要为那些从代码本身就能快速推断的事实写注释\n# Bad comment # ===========\r# y equals x plus 1\ry = x + 1\r# Good comment\r# ============\r# remove everything after the second *\rname = '*'.join(line.split('*')[:2])\r   避免为了注释而注释\n 比如重写一遍函数的输入变量    不要给不好的名字加注释，把名字改好\n 好代码 \u0026gt; 坏代码 + 好注释      用代码记录你的思想\n  好的注释就是写代码中产生的重要想法\n  电影制作者在其中给出自己的见解来通过讲故事来帮助你理解这部电影如何制作的。代码的注释也应该起到类似的效果\n  为代码的瑕疵写注释\n       标记 通常的意义     TODO 我还没有处理的事   FIXME 已知的无法运行的代码   HACK 对一个问题不得不采用的比较粗糙的解决方案   XXX 危险！这里有很重要的事      代码如何改动的想法应该被记录下来。此类注释帮助读者认识代码当前的质量和状态，甚至可以指导未来代码的改进方向\n  给常量加注释\n 记录下决定这个常量值时的想法    站在读者的角度，去想象他们需要知道什么\n 想象你的代码对于外人看起来是什么样子的，这个人并不熟悉你的项目 将细节写在注释中，解释为什么代码这么写而不那么写的内在理由 为普通读者意料之外的行为加上注释 公布有可能存在的陷阱，未雨绸缪  与其让用户慢慢发现问题，不如提前告知风险   全局关的注释  解释系统的各个组成部分 文件级别的注释   总结性的注释  解释后面的代码块做什么 不能简单的说注释只能用于解释“为什么”的问题而不能用于说明“是什么”的问题， 具体问题具体分析。   只要能帮到用户理解代码的，就是好注释。    克服不敢写注释的方法\n 不管心里想什么，先写下来 读一下这段注释，改进    写出言简意赅的注释  注释应该有很高的信息/空间率\n   让注释保持紧凑\n  避免使用不明确的代词\n it, this到底指什么    润色粗糙的注释\n  精确的描述函数的行为\n 如统计行数的行数，定义清楚行数到底怎么统计的，是数 \\n 呢还是数 \\r 呢？    用输入输出的例子来说明特别情况\n 有些时候一个好的例子顶的上很多句话    要包含新的新信息，而非解释代码字面上的意思。从高层次解释这段程序做了什么\n 这样做的好处在于可以让读者明白作者真正的意图，可能与实际代码有冲突，起到了冗余检查的角色    让函数的参数有名字\nConnect(timeout=10, use_encryption=False)\r Connect(/* timeout_ms = */10, /* use_encryption */ = False)\r   采用信息量很高的词，代替经常出现的编程场景\n Caching layer heurisitc bruteforce naive solution    二、简化循环和逻辑 让控制流变得易读  避免复杂的逻辑，巨大的表达式，一大堆变量，因为这增加了我们的思维包袱，这与容易理解矛盾，容易引起 bug 。\n   条件语句中参数的顺序\n   比较的左侧 比较的右侧     被查询的表达式，偏变量 被比较的表达式，偏常量    这条原则和英文（中文）的语法一致\n  if/else 的顺序\n 先处理正逻辑 先处理简单情况 先处理有趣、可疑的情况 前三者有冲突时，视情况决定    条件表达式\n 相对于追求最小化的代码行数，一个更好的度量方法是最小化人们理解的时间 默认使用 if/else 只在最简单的情况下，使用简化的语法糖    避免do/while 语句，尽量让条件判断出现在最前面\n  从函数中提前返回没有问题，只要保证调用函数结尾的清理代码就行\n  慎用goto\n  最小化嵌套\n 当对代码进行改动时，从全新的角度审视它，把它作为一个整体来看。 通过提早返回来减少嵌套  每一个if 都以return 或 continue 结束      谨慎的对待语言的高级特性，确保我们清楚代码的执行流程\n  拆分超长的表达式  代码中的表达式越长，越难以理解，尝试把它拆成若干的小块\n   总结变量\n 讲一个表达式用总结变量存下来，后面再复用这个总结变量    使用德摩根定理 De Morgan\u0026rsquo;s laws\n 非 (P 且 q) = (非 p) 或 (非 q) 非 (p 或 q) = (非 p) 且 (非 q)    避免滥用短路逻辑\n尽管有些语言存在特性if(a||b)  在 a 为真是不会执行 b\n还是老老实实用 if/else比较好\n  小心智能的小代码段，它们除了炫技毫无意义，只会去让人困惑，不利于后期维护\n  拆分复杂逻辑的一个方向是尝试它的逆逻辑\n  多个一样的表达式可以提取出来成为变量\n 避免录入错误 减少行宽，更易阅读 方便改动，不必多次修改同类代码    用宏简化重复的同类表达\n  变量与可读性  跟踪变量的三个问题\n 变量越多，就越难全部跟踪它们的动向 变量作用域越大，就需要跟踪它们的动向越久 变量改动的越平凡，就越难确定它们的当前值     减少变量\n 减少没有价值的临时变量  没有拆分复杂的表达式 没有做出更多的澄清 只用了一次，没有压缩任何冗余   减少用来保存中间结果的变量 减少控制流变量  这类变量唯一的目的就是控制程序的执行 这类变量可以用更好地结构化编程来消除 有多层循环时，可以把循环中的代码或者整个循环挪到一个新函数中 微软的 Eric Brechner 说过：“一个好的面试题起码要涉及三个变量。” 因为同时处理三个变量可以强迫人努力思考，但是我们的代码并不是用来面试我们的同事的。      缩小变量的作用域\n 让你的变量对尽量少的代码行可见\n   如果有一个类变量只有两个方法调用了，那么就可以把这个类变量降格成局部变量，因为它不需要被其他方法看见\n  把定义下移\n 原来C语言要求有所变量在代码最前面声明 现在可以在它使用前才声明      只写一次的变量更好\n  三、重新组织代码 三种组织函数级别代码的改动\n 抽取出那些与程序主要目的不相关的子问题，变成新的函数 重新组织代码，使它们一次只做一件事 先用自然语言描述代码，再用这个描述帮助找到更整洁的解决方案  抽取不相干的子问题   纯工具代码可以自己写或者调库\n 文件 I/O 操作字符串 哈希表    创建大量通用的代码\n 从项目其他部分中解耦出来 容易开发\u0026amp;测试 项目的其他部分会更小且更容易思考    简化已有的接口\n 永远不要安于使用不理想的接口 创建自己的包装函数来隐藏粗陋的接口    必要时，按需要重塑接口\n  避免过犹不及，不要引入过多的小函数\n  一次只做一件事  应该把代码组织的一次只做一件事\n 这个原则不仅适用于一个小函数，而且适用于将大的业务函数整理有序\n流程：\n 列出代码所需做的所有任务 尽量把这件任务拆分到不同的函数中，或者至少是代码的不同段落中   从对象中抽取需要的值  比如对象是一个字典，我们需要这个字典的若干的键对应的值，可以将这写值保存在变量中，抽取出来。这样就不必记住复杂的健值了    Tips\n`a||b||c` 可以返回第一个真值\r 把想法变成代码  如果你不能把一件事解释给你的祖母听的话说明你还没有真正理解它。 ​\t阿尔伯特 爱因斯坦\n 编写清晰代码的方法\n 像对着一个同事一样用自然语言描述代码要做什么 注意描述中的关键词 写出与所描述匹配的代码   清楚的描述逻辑 了解已有的函数库 运用递归  少写代码  最好的代码就是没有代码\n 写代码的最高境界就是不写代码。\n这句话虽有调侃之意，却隐含着哲学思辨，时刻问自己，我们真的需要写这些代码吗？\n不要低估写代码的时间，因为实现或许不费功夫，但是将来的代码库的维护，都会增加时间\n  质疑和拆分你的需求\n 有时候，解决一半问题可能只需要花费四分之一的时间 消除不必要的功能    保持小代码库\n 创建越来越多的“工具”代码来减少重复代码（第十章） 减少无用代码或者没有用的功能 让项目分开保持子项目状态 总的来说，小心代码的重量。保持轻灵    类似植物剪枝，代码也应该勤快的修剪\n 创造性的工作都不会保留之前所有的工作，比如电影、音乐、作者    熟悉周边的库\n 其实现有的库可以解决大部分问题，不要重复造轮子，我们的时间更重要。 使用 UNIX 命令行代替代码    避免过度设计\n  用最简单的方法完成工作\n  四、精选话题 测试与可读性  测试应当具有可读性，以方便其他人可以舒服的更改或增加测试。\n   普遍的测试原则\n 应当对使用者隐去不重要的细节，以便其他更重要的细节突出    创建最小的测试声明\n 大多数测试的基本内容都能精练成 “对于这样的输入或情形， 期望有 这样的行为或输出”。    让错误消息具备可读性\n 更好版本的 assert()    更好的测试输入\n 应当选择一组最简单的输入，前提是它能完整的使用被测代码 简化输入值  又简单又能完成工作的测试值更好      一个功能，多个测试\n 一个测试测试一个方向的bug，避免在一个测试函数内尝试所有情况    为测试函数命名\n  Test_\u0026lt;FunctionName\u0026gt;\n  Test_\u0026lt;FunctionName\u0026gt;_\u0026lt;situation\u0026gt;\n  测试函数的名字就是注释\n    测试驱动的开发 Test-Drive Development\n 解耦的最好的类往往是最容易测试的 避免程序内部类和类之间方法的调用 在写代码时想着测试就能有帮助，会促使我们停下来思考是否存在更好的设计 坏代码   好代码       特征 对测试的好处 对设计的好处     类只有很少的内部状态 很容易写出测试 更易理解   类/函数只做一件事 需要较少的测试用例 较小/简单的组件更加模块化，系统能有较低耦合   每个类对别的类依赖小，低耦合 每个类可以独立测试 系统可以并行开发，可以很容易的修改或者删除类，不会影响其他组件   函数接口简单，定义明确 有明确的行为可以测试，测试接口工作量小 接口更容易让程序员学习，复用概率高      避免走的太远（Don\u0026rsquo;t be too over）\n 牺牲真实代码的可读性 沉迷100%的测试覆盖率 考虑投入产出比，有些bug不值得测试 别让测试成为产品开发的阻碍   ","date":1541866380,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1541866380,"objectID":"73c6443edb8a8ae6ea187af5c00d75f5","permalink":"https://127.0.0.1/zh/post/notes-the-art-of-readable-code/","publishdate":"2018-11-11T00:13:00+08:00","relpermalink":"/zh/post/notes-the-art-of-readable-code/","section":"post","summary":"工作后，陆陆续续也做了几个项目，本书中所提到的几个注意点确实深有体会。这本能够围绕提高代码可读性这个原则，介绍了从变量名、注释、控制流、表达式、类/方法等多个方面优化代码的方法。这个读书笔记总结了作者的主要想法，起到了快速查阅的作用。\n","tags":null,"title":"读《编写可读代码的艺术》","type":"post"}]